{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0022cf7e",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7edf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities._network import *\n",
    "from utilities._training import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70770c13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88234deb",
   "metadata": {},
   "source": [
    "\n",
    "### Test with Different $\\alpha$ and $p$\n",
    "\n",
    "We choose $\\alpha = .2, .3, .4, .5$, $p = 97, 149$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fadc15d-e49e-4a13-8725-f4dec577c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prime, alpha = 97, .4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, test_loader = CustomDataLoader(alpha, 60, device, prime=prime)\n",
    "d_model, nhead, d_ff, ntoken = 128, 4, 512, prime\n",
    "model = Decoder(d_model, nhead, d_ff, ntoken).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.98), weight_decay=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a966733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train(model=model, train_dataloader=train_loader,test_dataloader=test_loader,optimizer=optimizer,loss_fn=loss_fn, epochs=3000,\n",
    "                            oriInfo=False, tsneInfo=False, add_test=False, complement=False, tolmax=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25745805",
   "metadata": {},
   "source": [
    "### Test Different Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STD\n",
    "torch.cuda.manual_seed_all(42)\n",
    "prime, alpha = 97, .3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, test_loader = CustomDataLoader(alpha, 60, device, prime=prime)\n",
    "d_model, nhead, d_ff, ntoken = 128, 4, 512, prime\n",
    "model = Decoder(d_model, nhead, d_ff, ntoken, dropout=.1).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.98), weight_decay=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e17a08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed_all(42)\n",
    "prime, alpha = 97, .3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, test_loader = CustomDataLoader(alpha, 60, device, prime=prime)\n",
    "d_model, nhead, d_ff, ntoken = 128, 4, 512, prime\n",
    "model = Decoder(d_model, nhead, d_ff, ntoken).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.98), weight_decay=0)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.98), weight_decay=0.15)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=.99, weight_decay=0)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=.99, weight_decay=2e-3)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=.99, weight_decay=0, nesterov=True)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=.99, weight_decay=2e-3, nesterov=True)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-3, momentum=0, weight_decay=0)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-3, momentum=0, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b43eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train(model=model, train_dataloader=train_loader,test_dataloader=test_loader,optimizer=optimizer,loss_fn=loss_fn,\n",
    "                epochs=500, tolmax=None, \n",
    "                oriInfo=False, tsneInfo=False, add_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f862d6b-7342-4009-ace2-6cb41d74d058",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb2cb3",
   "metadata": {},
   "source": [
    "### Test with Different $\\alpha$ and $p$\n",
    "\n",
    "We choose $\\alpha = .3, .4, .5, .6$, $p = 97, 149$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7fc3805-773c-4fe9-ae2a-136b4f8c5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "prime, alpha = 97, .6\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, test_loader = CustomDataLoader(alpha, 60, device, prime=prime)\n",
    "d_model, hidden, ntoken, layers = 128, 512, prime, 3\n",
    "model = ResMLP(d_model, hidden, ntoken, layers).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.98), weight_decay=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b928e29d-dc2d-40eb-9b3c-fca1ac6f64e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = train(model=model, train_dataloader=train_loader,test_dataloader=test_loader,optimizer=optimizer,loss_fn=loss_fn, epochs=10000,\n",
    "                oriInfo=False, tsneInfo=False, add_test=False, complement=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5abd398-cf9d-4b2c-927e-f7cffa9113e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bdb2ff",
   "metadata": {},
   "source": [
    "### Test with Different $\\alpha$ and $p$\n",
    "\n",
    "We choose $\\alpha = .3, .4, .5, .6$, $p = 97, 149$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e25fc40a-76f1-4c64-a25f-621fc5db4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "prime, alpha = 97, .6\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, test_loader = CustomDataLoader(alpha, 50, device, prime=97)\n",
    "d_model, hidden, ntoken, layers = 128, 512, prime, 2\n",
    "model = LSTM(d_model, hidden, ntoken, layers).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.98), weight_decay=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3da11-8056-4715-8970-1c50779d170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train(model=model, train_dataloader=train_loader,test_dataloader=test_loader,optimizer=optimizer,loss_fn=loss_fn, epochs=10000,\n",
    "               oriInfo=False, tsneInfo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b9636",
   "metadata": {},
   "source": [
    "## K SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5aedf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "prime, alpha, k = 47, .10, 3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, test_loader = KDataLoader(alpha, 512, device, prime=prime, k=k)\n",
    "d_model, nhead, d_ff, ntoken = 128, 4, 512, prime\n",
    "model = Decoder(d_model, nhead, d_ff, ntoken, max_len=k+2).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.98), weight_decay=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393182d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = train(model=model, train_dataloader=train_loader,test_dataloader=test_loader,optimizer=optimizer,loss_fn=loss_fn, epochs=10000,\n",
    "                   oriInfo=False, tsneInfo=False, add_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b6671-5b88-4728-9fa1-ab792f02f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prime, alpha, k = 23, .03, 4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, test_loader = KDataLoader(alpha, 512, device, prime=prime, k=k)\n",
    "d_model, nhead, d_ff, ntoken = 128, 4, 512, prime\n",
    "model = Decoder(d_model, nhead, d_ff, ntoken, max_len=k+2).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.98), weight_decay=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae77231-da93-44d6-814a-e2696dfffde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train(model=model, train_dataloader=train_loader,test_dataloader=test_loader,optimizer=optimizer,loss_fn=loss_fn, epochs=10000,\n",
    "                    oriInfo=False, tsneInfo=False, add_test=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
